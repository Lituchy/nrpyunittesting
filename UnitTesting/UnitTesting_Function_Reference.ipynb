{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing Functions Reference\n",
    "\n",
    "## Author: Kevin Lituchy\n",
    "\n",
    "## Introduction:\n",
    "This module contains in-depth explanations of all the functions in `UnitTesting`.If you have not already, please read through the Jupyter notebook [tutorial](../Tutorial-UnitTesting.ipynb) for unit testing. This will contain in-depth information on all functions used for unit testing, not a high-level user tutorial. With examples, the default module that will be used is `UnitTesting/Test_UnitTesting/test_module.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "\n",
    "# Table of Contents\n",
    "$$\\label{toc}$$\n",
    "\n",
    "This module is organized as follows:\n",
    "\n",
    "1. [failed_tests](#failed_tests)\n",
    "1. [standard_constants](#standard_constants)\n",
    "1. [run_NRPy_UnitTests](#run_NRPy_UnitTests)\n",
    "1. [create_test](#create_test)\n",
    "1. [setup_trusted_values_dict](#setup_trusted_values_dict)\n",
    "1. [run_test](#run_test)\n",
    "1. [evaluate_globals](#evaluate_globals)\n",
    "1. [cse_simplify_and_evaluate_sympy_expressions](#cse_simplify_and_evaluate_sympy_expressions)\n",
    "1. [create_dict_string](#create_dict_string)\n",
    "1. [first_time_print](#first_time_print)\n",
    "1. [calc_error](#calc_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='failed_tests'></a>\n",
    "\n",
    "# failed_tests:\n",
    "$$\\label{failed_tests}$$\n",
    "\n",
    "`failed_tests.txt` is a simple text file that keeps track of which tests\n",
    "failed. Line 1 is by default 'Failures: '. The subsequent lines tell the\n",
    "user which test functions in which test files failed in the following\n",
    "format: `[test file path]: [test function]`\n",
    "\n",
    "Example:\n",
    "\n",
    "Say that the test function `test_module_for_testing_no_gamma()` failed.\n",
    "Then we'd expect `failed_tests.txt` to be the following:\n",
    "\n",
    "```\n",
    "Failures:\n",
    "\n",
    "UnitTesting/Test_UnitTesting/test_module.py: test_module_for_testing_no_gamma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='standard_constants'></a>\n",
    "\n",
    "# standard_constants:\n",
    "$$\\label{standard_constants}$$\n",
    "\n",
    "`standard_constants.py` stores test-wide information that the user can\n",
    "modify to impact the numerical result for their globals. It currently\n",
    "only has one field, `precision`, which determines how precise the values\n",
    "for the globals are. It is by default set to `30`, which we've\n",
    "determined to be a reasonable amount. This file has the ability to be\n",
    "expanded upon in the future, but it is currently minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run_NRPy_UnitTests'></a>\n",
    "\n",
    "\n",
    "# run_NRPy_UnitTests:\n",
    "$$\\label{run_NRPy_UnitTests}$$\n",
    "\n",
    "`run_NRPy_UnitTests.sh` is a bash script that acts as the hub for\n",
    "running tests -- it is where the user specifies the tests they'd like to\n",
    "be run. It keeps track of which tests failed by interacting with\n",
    "[failed_tests](#failed_tests), giving the user easily readable output\n",
    "from the file. It also has the option to automatically rerun the tests\n",
    "that failed in `DEBUG` mode if the boolean `rerun_if_fail` is `true`.\n",
    "\n",
    "The script is run with the following syntax:\n",
    "\n",
    "```\n",
    "./UnitTesting/run_NRPy_UnitTests.sh [python interpreter]\n",
    "```\n",
    "\n",
    "This of course assumes that the user is in the nrpy directory; the user\n",
    "simply has to specify the path from their current directory to the bash\n",
    "file.\n",
    " \n",
    "Examples of `python interpreter` are `python` and `python3`.\n",
    "\n",
    "The script first lets the user know if they forgot to pass a python\n",
    "interpreter. Then if they didn't, it prints some baseline information\n",
    "about Python variables: `PYTHONPATH`, `PYTHONEXEC`, and `PYTHONEXEC`\n",
    "version.\n",
    "\n",
    "`failed_tests.txt` is then overwritten with the default information.\n",
    "This makes it so that each subsequent test call has a unique list of the\n",
    "tests that passed; it wouldn't make sense to store this information.\n",
    "\n",
    "The user can then change the boolean `rerun_if_fail` if need be. Next,\n",
    "the user can add tests using the `add_test` function. The syntax is as\n",
    "follows: `add_test [path to test file]`\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "add_test UnitTesting/Test_UnitTesting/test_module.py\n",
    "```\n",
    "\n",
    "Finally, the bash script will read any failures from `failed_tests.txt`\n",
    "and, if `rerun_if_fail` is `true`, rerun those tests. It lastly prints\n",
    "which tests failed in the same format as `failed_tests.txt`, and if no\n",
    "tests failed, a success message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create_test'></a>\n",
    "\n",
    "# create_test:\n",
    "$$\\label{create_test}$$\n",
    "\n",
    "create_test is a function that takes the following user-supplied\n",
    "information: a module to test `module`, the name of the module\n",
    "`module_name`, and a dictionary whose keys are functions and whose\n",
    "values are lists of globals `function_and_global_dict`. It uses this\n",
    "information to generate a test file that is automatically run as a bash\n",
    "script; this test file does all the heavy lifting in calling the\n",
    "function, getting expressions for all the globals, evaluating the\n",
    "expressions to numerical values, and storing the values in the proper\n",
    "trusted_values_dict.\n",
    "\n",
    "create_test additionally takes optional arguments `logging_level` and\n",
    "`initialization_string_dict`, which respectively determine the desired\n",
    "level of output (think verbosity) and run some python code prior calling\n",
    "the specified function. Usage is as following:\n",
    "\n",
    "```\n",
    "module = 'BSSN.BrillLindquist'\n",
    "\n",
    "module_name = 'BrillLindquist'\n",
    "\n",
    "function_and_global_dict = {'BrillLindquist(ComputeADMGlobalsOnly = True)': ['alphaCart', 'betaCartU', 'BCartU', 'gammaCartDD', 'KCartDD']}\n",
    "\n",
    "create_test(module, module_name, function_and_global_dict)\n",
    "```\n",
    "\n",
    "The way to think of this is that the module to be tested is\n",
    "BSSN.BrillLindquist. The module_name is how you refer to this module --\n",
    "it's a bit arbitrary, so whether you prefer BrillLindquist or bl, it\n",
    "won't change the computation. The function_and_global_dict contains\n",
    "entry 'BrillLindquist(ComputeADMGlobalsOnly = True)', which is the\n",
    "function that gets called in the module. It's value in the dictionary is\n",
    "a list of globals that get created when this function gets called.\n",
    "\n",
    "Now let's add the optional arguments into the same example:\n",
    "\n",
    "```\n",
    "module = 'BSSN.BrillLindquist'\n",
    "\n",
    "module_name = 'BrillLindquist'\n",
    "\n",
    "function_and_global_dict = {'BrillLindquist(ComputeADMGlobalsOnly = True)': ['alphaCart', 'betaCartU', 'BCartU', 'gammaCartDD', 'KCartDD']}\n",
    "\n",
    "logging_level = 'DEBUG'\n",
    "\n",
    "initialization_string_dict = {'BrillLindquist(ComputeADMGlobalsOnly = True)': 'print(\"example\")\\nprint(\"Hello world!\")'}\n",
    "\n",
    "create_test(module, module_name, function_and_global_dict, logging_level=logging_level, initialization_string_dict=initialization_string_dict)\n",
    "```\n",
    "\n",
    "Now when create_test runs, the user will be given much more output due\n",
    "to the logging_level; additionally, the user-specified print will occur\n",
    "due to initialization_string_dict.\n",
    "\n",
    "You may now be wondering why we use dictionaries to store this data\n",
    "instead of simply having separate variables `function`, `global_list`,\n",
    "and `initialization_string`. This is where some of the power of this\n",
    "testing method lies: we can test multiple functions and their globals\n",
    "with ease! In other words, function_and_global_dict can contain multiple\n",
    "entries, each a specific function call with its own associated list of\n",
    "globals. Since not every function being tested must have an associated\n",
    "initialization_string, we make an entry for each function optional. An\n",
    "example is as follows:\n",
    "\n",
    "```\n",
    "module = 'BSSN.BrillLindquist'\n",
    "\n",
    "module_name = 'BrillLindquist'\n",
    "\n",
    "function_and_global_dict = {'BrillLindquist(ComputeADMGlobalsOnly = True)': ['alphaCart', 'betaCartU', 'BCartU', 'gammaCartDD', 'KCartDD'],\n",
    "                            'BrillLindquist(ComputeADMGlobalsOnly = False)': ['alphaCart', 'betaCartU', 'BCartU', 'gammaCartDD', 'KCartDD']}\n",
    "\n",
    "logging_level = 'DEBUG'\n",
    "\n",
    "initialization_string_dict = {'BrillLindquist(ComputeADMGlobalsOnly = True)': 'print(\"example\")\\nprint(\"Hello world!\")'}\n",
    "\n",
    "create_test(module, module_name, function_and_global_dict, logging_level=logging_level, initialization_string_dict=initialization_string_dict)\n",
    "```\n",
    "\n",
    "Both instances will be called separately, with their own globals. The\n",
    "print statements will only be called in the first function, since there\n",
    "is no associated initialization_string for the second function as well.\n",
    "\n",
    "An important note when using `create_test` is that all arguments are\n",
    "**strings**. This includes the module, module_name, function, each\n",
    "global in the list of globals, logging level, and initialization_string.\n",
    "The reason for making these fields strings is that when setting\n",
    "module_name, for example, there doesn't exist anything in Python with\n",
    "the name BrillLindquist. So, we wrap it in a string. This is true of\n",
    "every input. Be careful with the dicts and lists, however: their\n",
    "arguments are strings, they aren't themselves strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_trusted_values_dict'></a>\n",
    "\n",
    "# setup_trusted_values_dict:\n",
    "$$\\label{setup_trusted_values_dict}$$\n",
    "\n",
    "`setup_trusted_values_dict` takes in a path to a test directory `path`,\n",
    "and checks whether or not a `trusted_values_dict.py` exists in the test\n",
    "directory. If it does exist, the function does nothing. If it doesn't\n",
    "exist, `setup_trusted_values_dict` creates the file\n",
    "`trusted_values_dict.py` in the test directory. In then writes the\n",
    "following default code into the file:\n",
    "\n",
    "```\n",
    "from mpmath import mpf, mp, mpc\n",
    "from UnitTesting.standard_constants import precision\n",
    "\n",
    "mp.dps = precision\n",
    "trusted_values_dict = {}\n",
    "\n",
    "```\n",
    "\n",
    "The default code allows the unit test to properly interact with and\n",
    "write to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run_test'></a>\n",
    "\n",
    "# run_test:\n",
    "$$\\label{run_test}$$\n",
    "\n",
    "`run_test` acts as the hub for an individual unit test. It takes in all\n",
    "the module-wide information, and goes through all the steps of\n",
    "determining whether the test passed or failed by calling many\n",
    "sub-functions. A fundamentally important part of `run_test` is the\n",
    "notion of `self`; `self` stores a test's information (i.e. `module`,\n",
    "`module_name`, etc.) to be able to easily pass information to and make\n",
    "assertions in sub-functions. When `self` is referenced, simply think\n",
    "\"information storage\".\n",
    "\n",
    "`run_test` begins by importing the `trusted_values_dict` of the current\n",
    "module being tested; since `setup_trusted_values_dict` is called before\n",
    "`run_test`, we know it exists.\n",
    "\n",
    "`run_test` then determines if the current function/module is being done\n",
    "for the first time based off the existence of the proper entry in\n",
    "`trusted_values_dict`, and stores this boolean in `first_time`. \n",
    "\n",
    "[evaluate_globals](#evaluate_globals) is then run in order to generate\n",
    "the SymPy expressions for each global being tested. \n",
    "\n",
    "Next,\n",
    "[cse_simplify_and_evaluate_sympy_expressions](#cse_simplify_and_evaluate_sympy_expressions)\n",
    "is called to turn each SymPy expression for each global into a random, yet predictable/repeatable, number. \n",
    "\n",
    "The next step depends on the value of `first_time`: if `first_time` is `True`, then [first_time_print](#first_time_print) is run to print the result both to the console and to the `trusted_values_dict.py`. Otherwise, if `first_time` is `False`, [calc_error](#calc_error) is called in order to compare the calculated values and the trusted values for the current module/function. If an error was found, the difference is printed and the code exits. Otherwise, the module completes and returns.\n",
    "\n",
    "On it's own, `run_test` doesn't do much -- it's the subfunctions called by `run_test` that do the heavy lifting in terms of formatting, printing, calculating, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evaluate_globals'></a>\n",
    "\n",
    "# evaluate_globals:\n",
    "$$\\label{evaluate_globals}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cse_simplify_and_evaluate_sympy_expressions'></a>\n",
    "\n",
    "# cse_simplify_and_evaluate_sympy_expressions:\n",
    "$$\\label{cse_simplify_and_evaluate_sympy_expressions}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create_dict_string'></a>\n",
    "\n",
    "# create_dict_string:\n",
    "$$\\label{create_dict_string}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first_time_print'></a>\n",
    "\n",
    "# first_time_print:\n",
    "$$\\label{first_time_print}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calc_error'></a>\n",
    "\n",
    "# calc_error:\n",
    "$$\\label{calc_error}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
